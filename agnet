import os
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_milvus import Milvus

# 1. ì˜ˆì œ ë§¤ë‰´ì–¼ ë°ì´í„° ìƒì„± (íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜ ì„ì‹œ ìƒì„±)
manual_text = """
ì œí’ˆëª…: AI ì²­ì†Œê¸° X-2000 ì‚¬ìš©ì ë§¤ë‰´ì–¼
1. ì „ì› ì¼œê¸°: ë³¸ì²´ ìƒë‹¨ì˜ ë¹¨ê°„ìƒ‰ ë²„íŠ¼ì„ 3ì´ˆê°„ ëˆ„ë¥´ì„¸ìš”.
2. ì¶©ì „ ë°©ë²•: ë°°í„°ë¦¬ê°€ 20% ë¯¸ë§Œì¼ ë•Œ ìë™ìœ¼ë¡œ ì¶©ì „ ìŠ¤í…Œì´ì…˜ìœ¼ë¡œ ë³µê·€í•©ë‹ˆë‹¤. ìˆ˜ë™ ì¶©ì „ì€ í™ˆ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.
3. í•„í„° ì²­ì†Œ: ë¨¼ì§€í†µì„ ë¶„ë¦¬í•œ í›„, HEPA í•„í„°ë¥¼ ë¬¼ë¡œ ì„¸ì²™í•˜ê³  24ì‹œê°„ ê±´ì¡°í•˜ì„¸ìš”.
4. ì—ëŸ¬ ì½”ë“œ E-01: ë°”í€´ì— ì´ë¬¼ì§ˆì´ ë¼ì—ˆì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤. ë°”í€´ë¥¼ í™•ì¸í•˜ì„¸ìš”.
"""

with open("manual.txt", "w", encoding="utf-8") as f:
    f.write(manual_text)

def ingest_manual_to_milvus():
    # 2. ë¬¸ì„œ ë¡œë“œ
    loader = TextLoader("manual.txt", encoding="utf-8")
    docs = loader.load()

    # 3. ë¬¸ì„œ ë¶„í•  (Splitting)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
    splits = text_splitter.split_documents(docs)

    # 4. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embeddings = OpenAIEmbeddings()

    # 5. Milvusì— ì €ì¥ (Vector Store ìƒì„±)
    # connection_argsì— urië¥¼ íŒŒì¼ ê²½ë¡œë¡œ ì£¼ë©´ Milvus Liteê°€ ì‘ë™í•©ë‹ˆë‹¤.
    vector_store = Milvus.from_documents(
        documents=splits,
        embedding=embeddings,
        collection_name="user_manual_collection",
        connection_args={"uri": "./milvus_demo.db"}, # ë¡œì»¬ íŒŒì¼ DB ìƒì„±
        drop_old=True  # ë°ëª¨ìš©: ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
    )
    
    print("âœ… ë§¤ë‰´ì–¼ ë°ì´í„°ê°€ Milvusì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return vector_store

# ì‹¤í–‰í•˜ì—¬ DB êµ¬ì¶•
vector_store = ingest_manual_to_milvus()




from langchain.tools.retriever import create_retriever_tool

# 1. Retriever ìƒì„±
retriever = vector_store.as_retriever(search_kwargs={"k": 2}) # ìƒìœ„ 2ê°œ ê²°ê³¼ ê²€ìƒ‰

# 2. Agentê°€ ì‚¬ìš©í•  Toolë¡œ ë³€í™˜
tool = create_retriever_tool(
    retriever,
    name="manual_search",
    description="ì‚¬ìš©ì ë§¤ë‰´ì–¼ì—ì„œ ì œí’ˆ ì‚¬ìš©ë²•, ì—ëŸ¬ ì½”ë“œ, ì²­ì†Œ ë°©ë²• ë“±ì„ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
)

tools = [tool]





from typing import Annotated, Literal
from typing_extensions import TypedDict

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

# 1. ê·¸ë˜í”„ ìƒíƒœ(State) ì •ì˜
# messages ë¦¬ìŠ¤íŠ¸ì— ëŒ€í™” ê¸°ë¡ì´ ê³„ì† ì¶”ê°€ë˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]

# 2. LLM ëª¨ë¸ ì„¤ì • ë° ë„êµ¬ ë°”ì¸ë”©
llm = ChatOpenAI(model="gpt-4o", temperature=0)
llm_with_tools = llm.bind_tools(tools)

# 3. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜

def agent_node(state: AgentState):
    """
    í˜„ì¬ ìƒíƒœ(ëŒ€í™” ê¸°ë¡)ë¥¼ ë³´ê³  LLMì´ ì‘ë‹µí•˜ê±°ë‚˜ ë„êµ¬ í˜¸ì¶œì„ ê²°ì •í•˜ëŠ” ë…¸ë“œ
    """
    messages = state["messages"]
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

def should_continue(state: AgentState) -> Literal["tools", END]:
    """
    LLMì˜ ì‘ë‹µì„ ë³´ê³  ë„êµ¬ë¥¼ ì‹¤í–‰í•´ì•¼ í• ì§€, ì¢…ë£Œí•´ì•¼ í• ì§€ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¶€ ì—£ì§€
    """
    messages = state["messages"]
    last_message = messages[-1]
    
    # LLMì´ ë„êµ¬ í˜¸ì¶œ(tool_calls)ì„ ìš”ì²­í–ˆìœ¼ë©´ 'tools' ë…¸ë“œë¡œ ì´ë™
    if last_message.tool_calls:
        return "tools"
    # ì•„ë‹ˆë©´ ì¢…ë£Œ
    return END

# 4. ê·¸ë˜í”„ êµ¬ì„± (Graph Construction)
workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("agent", agent_node)
workflow.add_node("tools", ToolNode(tools)) # LangGraphê°€ ì œê³µí•˜ëŠ” ê¸°ë³¸ ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ


# ì—£ì§€(Edge) ì—°ê²°
workflow.add_edge(START, "agent")

# ì¡°ê±´ë¶€ ì—£ì§€: agent -> (íŒë‹¨) -> tools ë˜ëŠ” END
workflow.add_conditional_edges(
    "agent",
    should_continue,
)

# ë„êµ¬ ì‹¤í–‰ í›„ì—ëŠ” ë‹¤ì‹œ agentë¡œ ëŒì•„ì™€ì„œ ê²°ê³¼ë¥¼ í•´ì„í•˜ê²Œ í•¨
workflow.add_edge("tools", "agent")

# 5. ê·¸ë˜í”„ ì»´íŒŒì¼
app = workflow.compile()






from langchain_core.messages import HumanMessage

def ask_manual_agent(question: str):
    print(f"\nğŸ™‹ ì‚¬ìš©ì ì§ˆë¬¸: {question}")
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    inputs = {"messages": [HumanMessage(content=question)]}
    
    # streamì„ ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ ê³¼ì •ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    for event in app.stream(inputs):
        for key, value in event.items():
            print(f"  ğŸ”„ [Node: {key}] ì²˜ë¦¬ ì™„ë£Œ")
            # ë””ë²„ê¹…ìš©: ë„êµ¬ í˜¸ì¶œ ë‚´ìš© í™•ì¸
            if key == "agent" and value["messages"][0].tool_calls:
                 print(f"     ğŸ‘‰ ë„êµ¬ í˜¸ì¶œ: {value['messages'][0].tool_calls[0]['name']}")

    # ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
    final_state = app.invoke(inputs)
    print(f"ğŸ¤– ì—ì´ì „íŠ¸ ë‹µë³€: {final_state['messages'][-1].content}")

# --- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ---

# Case 1: ë§¤ë‰´ì–¼ì— ìˆëŠ” ë‚´ìš© ì§ˆë¬¸ (Milvus ê²€ìƒ‰ í•„ìš”)
ask_manual_agent("ë¹¨ê°„ë¶ˆ ì—ëŸ¬(E-01)ê°€ ë–´ëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•´?")

# Case 2: ë§¤ë‰´ì–¼ì— ìˆëŠ” ì²­ì†Œ ë°©ë²• ì§ˆë¬¸
ask_manual_agent("í•„í„°ëŠ” ì–´ë–»ê²Œ ì”»ì–´?")

# Case 3: ì¼ë°˜ì ì¸ ì¸ì‚¬ (ê²€ìƒ‰ ë¶ˆí•„ìš”)
ask_manual_agent("ì•ˆë…•, ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ?")
